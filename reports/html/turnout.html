<!doctype html>
<html lang="English">
<head>
<meta charset="utf-8">
<meta name="generator" content="pandoc">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Turnout Model & Predictions</title>

<!-- Yahoo! CDN combo URL for selected Pure.css modules -->
<link rel="stylesheet" href="http://yui.yahooapis.com/combo?pure/0.6.0/base-min.css&pure/0.6.0/grids-responsive-min.css&pure/0.6.0/menus-min.css&pure/0.6.0/tables-min.css">
<!-- MathJax -->
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- Vega and Vega Embed -->
<script src="https://cdn.jsdelivr.net/npm/vega@4.4.0"></script>
<script src="https://cdn.jsdelivr.net/npm/vega-lite@3.0.0-rc11"></script>
<script src="https://cdn.jsdelivr.net/npm/vega-embed@3.28.0"></script>

<!-- Extra styles -->
<style>
body{margin:10em 0 0}.pure-g{padding:0 1em}.pure-menu-link:focus{background-color:#d3d3d3}nav{margin:0 0 1em;padding:0 0 1em;border-bottom:1px solid #ccc}footer{margin:5em 0 1em}pre{white-space:pre-wrap;margin-left:3em}code{font-size:89%;color:#191919}.author{margin-bottom:0;padding-bottom:0}.headnote,.published,.license{font-size:89%;margin-bottom:.75em}@media screen and (max-width:35.5em){thead{display:none}tr,th,td{display:block}td{border-top:0}tr td:first-child{border-top:1px solid #ddd;font-weight:700}}
table {
    margin-left: auto;
    margin-right: auto;
    margin-bottom: 24px;
    border-spacing: 0;
    border-bottom: 2px solid black;
    border-top: 2px solid black;
}
table th {
    padding: 3px 10px;
    background-color: white;
    border-top: none;
    border-left: none;
    border-right: none;
    border-bottom: 1px solid black;
}
table td {
    padding: 3px 10px;
    border-top: none;
    border-left: none;
    border-bottom: none;
    border-right: none;
}
</style>

<script src="" type="text/javascript"></script>
</head>
<body>
<section id="page-content">
<div class="pure-g">
<div class="pure-u-1 pure-u-sm-1 pure-u-md-1 pure-u-lg-1 pure-u-xl-1">

<!-- page content begins here -->

<section id="model-notes" class="level2">
<h2>Model Notes</h2>
<p>Our goal is to use the 2016 house results to fit a very simple model of the electorate. We consider the electorate as having eight "identity" groups, split by sex (the census only records this as the F/M binary), age, young (&lt;45) and old (&gt;45) and racial identity (white or non-white). We recognize that these categories are limiting and much too simple. But we believe it's a reasonable starting point, as a balance between inclusiveness and having way too many variables.</p>
<p>For each congressional district where both major parties ran candidates (369 out of 438), we have census estimates of the number of people in each of our demographic categories. And from the census we have national-level turnout estimates for each of these groups as well. What we want to estimate, is how likely a voter in each group is of voting for the democratic candidate in a contested race.</p>
<p>We label our identity groups by a subscript <span class="math inline">\(i\)</span> and so, for each district, we have the set of expected voters (the number of people in each group, multiplied by the turnout for that group), <span class="math inline">\(\{V_i\}\)</span>, the number of democratic votes, <span class="math inline">\(D\)</span>, republican votes, <span class="math inline">\(R\)</span> and total votes, <span class="math inline">\(T\)</span>, which may exceed <span class="math inline">\(D + R\)</span> since there may be third party candidates. For the sake of simplicity, we assume that all groups are equally likely to vote for a third party candidate. And now we want to estimate <span class="math inline">\(p_i\)</span>, the probability that a voter in the <span class="math inline">\(i\)</span>th group--who votes for a republican or democrat!!--will vote for the democratic candidate.</p>
<ul>
<li><p>Bayes theorem relates the probability of a model (our probabilities <span class="math inline">\(\{p_i\}\)</span>), given the observed data (the number of democratic votes recorded in each district, <span class="math inline">\(\{D_k\}\)</span>) to the likelihood of observing that data given the model and our prior knowledge about the model: <span class="math inline">\(\begin{equation} P(\{p_i\}|\{D_k\}) = \frac{P(\{D_k\}|\{p_i\})P(\{p_i\})}{P(\{D_k\})} \end{equation}\)</span></p></li>
<li><p>What makes this useful is that <span class="math inline">\(P(\{D_k\}|\{p_i\})\)</span> is a thing we can compute. More on that later. <span class="math inline">\(P(\{p_i\})\)</span> is called a "prior" and amounts to an assumption about what we think we know about the parameters before we have seen any data. In practice, this can often be set to something very boring, in our case, we will assume that our prior is just that any <span class="math inline">\(p_i \in [0,1]\)</span> is equally likely.</p></li>
<li><p><span class="math inline">\(P(\{D_k\})\)</span> is the unconditional probability that we observed our data. This is difficult to compute! But, thankfully, what we are usually interested in is just finding the <span class="math inline">\(\{p_i\}\)</span> which maximize <span class="math inline">\(P(\{p_i\}|\{D_k\})\)</span> and, since <span class="math inline">\(P(\{D_k\})\)</span> doesn't depend on <span class="math inline">\(\{p_i\}\)</span>, we don't need to know what it is.</p></li>
<li><p>Back to the computation of <span class="math inline">\(P(\{D_k\}|\{p_i\})\)</span>, the probability that we observed our evidence, given a specific set of <span class="math inline">\(\{p_i\}\)</span>. Our <span class="math inline">\(p_i\)</span> are the probability that one voter of type <span class="math inline">\(i\)</span> votes for the democrat. Given <span class="math inline">\(V_i\)</span> voters of that type, the distribution of democratic votes <em>from that type of voter</em> is Bernoulli, with <span class="math inline">\(V_i\)</span> trials and <span class="math inline">\(p_i\)</span> probability of success. But <span class="math inline">\(V_i\)</span> is quite large! So we can approximate this with a normal distribution with mean <span class="math inline">\(V_i p_i\)</span> and variance <span class="math inline">\(V_i p_i (1 - p_i)\)</span> (See <a href="https://en.wikipedia.org/wiki/Binomial_distribution#Normal_approximation">Wikipedia</a>). However, we can't observe the number of votes from just one type of voter. We can only observe the sum over all types. Luckily, the sum of normally distributed random variables is also normal. So the distribution of democratic votes across all types of voters is also normal, with mean <span class="math inline">\(\sum_i V_i p_i\)</span> and variance <span class="math inline">\(\sum_i V_i p_i (1 - p_i)\)</span> (See <a href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables">Wikipedia</a>). Thus we have <span class="math inline">\(P(D_k|\{p_i\})\)</span>, or, what amounts to the same thing, its density. But that means we also know <span class="math inline">\(P(\{D_k\}|\{p_i\})\)</span> since that is just the product of the normal distribution for each <span class="math inline">\(D_k\)</span>:</p></li>
</ul>
<p><span class="math inline">\(\begin{equation} \mu_k(\{p_i\}) = \sum_i V_i p_i\\ v_k(\{p_i\}) = \sum_i V_i p_i (1 - p_i)\\ p(D_k|\{p_i\}) = \frac{1}{\sqrt{2\pi v_k}}e^{-\frac{(D_k -\mu_k(\{p_i\}))^2}{2v_k(\{p_i\})}}\\ p(\{D_k\}|\{p_i\}) = \Pi_k p(D_k|\{p_i\}) \end{equation}\)</span></p>
<div style="display: inline-block; padding: 7px; border-collapse: collapse">
<span>Regression Details</span>
<table>
<thead>
<tr class="header">
<th>parameter</th>
<th>estimate</th>
<th>95% confidence</th>
<th>p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>YoungWhiteMale</td>
<td>1.327</td>
<td>4.398</td>
<td>0.118</td>
</tr>
<tr class="even">
<td>OldWhiteMale</td>
<td>-1.606</td>
<td>3.901</td>
<td>0.053</td>
</tr>
<tr class="odd">
<td>YoungWhiteFemale</td>
<td>-0.483</td>
<td>4.148</td>
<td>0.324</td>
</tr>
<tr class="even">
<td>OldWhiteFemale</td>
<td>1.941</td>
<td>3.423</td>
<td>0.013</td>
</tr>
<tr class="odd">
<td>YoungNonWhiteMale</td>
<td>1.321</td>
<td>9.646</td>
<td>0.295</td>
</tr>
<tr class="even">
<td>OldNonWhiteMale</td>
<td>0.455</td>
<td>10.007</td>
<td>0.429</td>
</tr>
<tr class="odd">
<td>YoungNonWhiteFemale</td>
<td>1.369</td>
<td>7.080</td>
<td>0.224</td>
</tr>
<tr class="even">
<td>OldNonWhiteFemale</td>
<td>1.238</td>
<td>7.116</td>
<td>0.247</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>Summary Stat.</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>R-Squared</td>
<td>0.297</td>
</tr>
<tr class="even">
<td>Adj. R-squared</td>
<td>0.282</td>
</tr>
<tr class="odd">
<td>F-stat</td>
<td>21.837</td>
</tr>
<tr class="even">
<td>p-value</td>
<td>0.000</td>
</tr>
<tr class="odd">
<td>Mean Squared Error</td>
<td>2961466832.183</td>
</tr>
</tbody>
</table>
</div>
<figure id="turnoutRegressionCoeffs">
<script type="text/javascript">var vlSpec=
{
    "transform": [
        {
            "as": "estLo",
            "calculate": "datum.Estimate - datum.Confidence/2"
        },
        {
            "as": "estHi",
            "calculate": "datum.Estimate + datum.Confidence/2"
        }
    ],
    "config": {
        "view": {
            "height": 400,
            "width": 800
        },
        "padding": 50
    },
    "data": {
        "values": [
            {
                "Confidence": 4.397883605655653,
                "Key": "",
                "Estimate": 1.3271121393621679,
                "Parameter": "YWM"
            },
            {
                "Confidence": 3.901485309813411,
                "Key": "",
                "Estimate": -1.6062392336402371,
                "Parameter": "OWM"
            },
            {
                "Confidence": 4.148357360150986,
                "Key": "",
                "Estimate": -0.4831751161854496,
                "Parameter": "YWF"
            },
            {
                "Confidence": 3.422879803858133,
                "Key": "",
                "Estimate": 1.9410171333896262,
                "Parameter": "OWF"
            },
            {
                "Confidence": 9.646336519014216,
                "Key": "",
                "Estimate": 1.3214975360949328,
                "Parameter": "YNWM"
            },
            {
                "Confidence": 10.006661585548908,
                "Key": "",
                "Estimate": 0.4546606727040245,
                "Parameter": "ONWM"
            },
            {
                "Confidence": 7.08043449139153,
                "Key": "",
                "Estimate": 1.3693000316114596,
                "Parameter": "YNWF"
            },
            {
                "Confidence": 7.115761185550205,
                "Key": "",
                "Estimate": 1.2375678643603132,
                "Parameter": "ONWF"
            }
        ]
    },
    "$schema": "https://vega.github.io/schema/vega-lite/v2.json",
    "title": "Parameters",
    "layer": [
        {
            "mark": "point",
            "encoding": {
                "color": {
                    "field": "Key",
                    "type": "nominal",
                    "legend": null
                },
                "x": {
                    "field": "Estimate",
                    "type": "quantitative",
                    "axis": {
                        "title": "Estimate (with 95% confidence error bars)"
                    }
                },
                "y": {
                    "field": "Parameter",
                    "type": "ordinal"
                }
            }
        },
        {
            "mark": "rule",
            "encoding": {
                "x2": {
                    "field": "estHi",
                    "type": "quantitative",
                    "axis": {
                        "title": ""
                    }
                },
                "color": {
                    "field": "Key",
                    "type": "nominal",
                    "legend": null
                },
                "x": {
                    "field": "estLo",
                    "type": "quantitative",
                    "axis": {
                        "title": ""
                    }
                },
                "y": {
                    "field": "Parameter",
                    "type": "ordinal"
                }
            }
        }
    ]
};
vegaEmbed('#turnoutRegressionCoeffs',vlSpec);</script>
</figure>
</section>

<!-- page content ends here -->

</div>     <!-- pure-u-1... -->
</div>     <!-- pure-g -->
</section> <!-- page-content -->
<div class="pure-g">
<footer><a href="https://bitfragment.github.io/mindoc">mindoc</a> v1.1.0</footer>
</div>
<script>
var mindoc=function(){function e(e){return e=e.toLowerCase(),e.charAt(0).toUpperCase()+e.substr(1)}function n(e){var n=new RegExp(/^\b[a-z]\S+\b-\b\S+\b/);return n.test(e)&&(e=e.replace(/-+/g," ")),e}function t(t){return t=n(t),e(t)}function r(e,n){return!!e.className.match(new RegExp("(\\s|^)"+n+"(\\s|)"))}function a(e,n){r(e,n)||(e.className+=" "+n)}function o(e,n){if(r(e,n)){var t=new RegExp("(\\s|^)"+n+"(\\s|)");e.className=e.className.replace(t," ")}}function u(){var e,n,t={table:"pure-table pure-table-bordered"};Object.keys(t).forEach(function(r){if(e=document.getElementsByTagName(r),n=e.length,n>1)for(var o=0;n>o;o++)a(e[o],t[r])})}function c(e,n){for(var t=0,r=e.length;r>t;t++)for(var a=e[t].getElementsByTagName("a"),u=0,c=a.length;c>u;u++)a[u].addEventListener("click",function(){o(n,"hidden")})}function i(e,n){for(var t=0,r=e.length;r>t;t++)e[t].addEventListener("click",function(){o(n,"hidden")})}function d(){var e=document.createElement("li");return a(e,"pure-menu-item"),e}function l(e){var n=document.createElement("a");return n.id="menu-"+e,n.href="#",n.innerHTML=t(e),a(n,"pure-menu-link"),n}function m(e){var n=document.createDocumentFragment(),t=document.createElement("nav"),r=document.createElement("div"),o=document.createElement("ul");n.appendChild(t),t.appendChild(r),r.appendChild(o),a(r,"pure-menu"),a(o,"pure-menu-list");var u="All sections",c=d();a(c,"pure-menu-selected"),o.appendChild(c),c.appendChild(l(u));for(var i,m,s=0,f=e.length;f>s;s++)i=e[s].getAttribute("id"),m=d(),o.appendChild(m),m.appendChild(l(i));var p=document.getElementById("page-content");document.querySelector("body").insertBefore(n,p)}function s(e){var n;e.hasAttribute("pure-menu-selected")||(n=document.querySelector(".pure-menu-selected"),o(n,"pure-menu-selected"),a(e,"pure-menu-selected"))}function f(e,n){var t,u=n.getAttribute("id"),c=u.replace(/menu-/,""),i=document.getElementById(u).parentNode;s(i);for(var d in e)t=e[d],r(t,"hidden")||a(t,"hidden"),t.getAttribute("id")===c&&r(t,"hidden")&&o(t,"hidden")}function p(e){var n;for(var t in e)n=e[t],r(n,"hidden")&&o(n,"hidden")}function v(e){for(var n=document.querySelectorAll(".pure-menu-link"),t=0,r=n.length;r>t;t++)0===t?n[t].addEventListener("click",function(){p(e)}):n[t].addEventListener("click",function(){f(e,this)})}return{main:function(){if(u(),document.getElementsByClassName("level2").length>0){var e,n=[];["abstract","level2","footnotes"].forEach(function(t){e=document.getElementsByClassName(t);for(var r=0,a=e.length;a>r;r++)n.push(e[r])});var t;for(var o in n)t=n[o],r(t,"level2")||a(t,"level2"),r(t,"footnotes")&&t.setAttribute("id","footnotes");m(n),v(n);var d=document.getElementsByClassName("citation"),l=document.getElementById("references");c(d,l);var s=document.getElementsByClassName("footnoteRef"),f=document.getElementById("footnotes");i(s,f)}}}}();window.addEventListener("load",function(){mindoc.main()});
</script>

<!-- For debugging local scripts -->
<!-- <script src="../build/mindoc.js"></script> -->
</body>
</html>
